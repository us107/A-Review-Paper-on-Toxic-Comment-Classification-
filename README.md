# Toxic Comment Classification

This paper focuses on the automatic classification of toxic comments using machine learning and natural language processing techniques. It addresses the growing challenge of hate speech, harassment, and inappropriate content on online platforms, aiming to promote safer digital interactions.

## Features
- **Machine Learning Models**: Logistic Regression, SVM, Decision Trees, and advanced deep learning models like LSTM and BERT.
- **Data Imbalance Handling**: Oversampling, undersampling, and synthetic data generation (SMOTE).
- **Explainability**: Utilizes techniques like LIME and SHAP for model interpretability.
- **Dataset Support**: Works with widely-used datasets like Jigsaw, Wikipedia Comments, and Kaggle Toxic Comment datasets.

## Goals
- Enhance online moderation with automated tools.
- Improve safety and foster respectful interactions in digital spaces.
- Address challenges like language complexity, data imbalance, and contextual sensitivity.

## Contributions
This research provides insights into the effectiveness of machine learning and NLP models for toxic comment classification, paving the way for robust, transparent, and context-sensitive moderation systems.

## Authors
- **Trisha Sharma**  
- **Anahita Bhandari**  

## License
This project is licensed under the [MIT License](LICENSE).

## Acknowledgments
- Datasets: Jigsaw, Wikipedia Comments, Kaggle Toxic Comment datasets.
- References: Research works on toxic comment classification and NLP techniques.
